{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Import Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Done\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_svmlight_files\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from pprint import pprint\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.preprocessing import binarize\n",
    "from time import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "print('Import Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading datasets...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Reading datasets...')\n",
    "load_files = [\"/data/aclImdb/train/labeledBow.feat\",\"/data/aclImdb/test/labeledBow.feat\"]\n",
    "#importing files as string for TF_IDF\n",
    "train_review,train_rating,test_review,test_rating = load_svmlight_files(load_files,n_features=None, dtype=str, multilabel=False, zero_based='auto', query_id=False)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing first and last Training records to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Training ratings:\n",
      "9.0\n",
      "7.0\n",
      "9.0\n",
      "10.0\n",
      "8.0\n",
      "10.0\n",
      "10.0\n",
      "7.0\n",
      "7.0\n",
      "7.0\n",
      "Last 10 Training ratings:\n",
      "1.0\n",
      "2.0\n",
      "4.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "4.0\n",
      "2.0\n",
      "2.0\n",
      "Last 10 Test ratings:\n",
      "10.0\n",
      "10.0\n",
      "7.0\n",
      "7.0\n",
      "10.0\n",
      "7.0\n",
      "7.0\n",
      "9.0\n",
      "9.0\n",
      "7.0\n",
      "Last 10 Test ratings:\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#Print this if wnat to see the ratings labels before conversion i.e.0-9\n",
    "print(\"First 10 Training ratings:\")\n",
    "for i in range(0,10):\n",
    "    print(train_rating[i])\n",
    "print(\"Last 10 Training ratings:\")\n",
    "for i in range(24990,25000):\n",
    "    print(train_rating[i])\n",
    "print(\"Last 10 Test ratings:\")\n",
    "for i in range(0,10):\n",
    "    print(test_rating[i])\n",
    "print(\"Last 10 Test ratings:\")\n",
    "for i in range(24990,25000):\n",
    "    print(test_rating[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to binary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted to binary values\n"
     ]
    }
   ],
   "source": [
    "#manually iterating thorough all the records to convert all values to binary i.e 0 or 1\n",
    "binary_train_target = []\n",
    "binary_test_target = []\n",
    "for i in range(len(train_rating)):\n",
    "    if train_rating[i] > 5:\n",
    "        binary_train_target.append(1)\n",
    "    elif train_rating[i] <= 5:\n",
    "        binary_train_target.append(0)\n",
    "for i in range(len(test_rating)):\n",
    "    if test_rating[i] > 5:\n",
    "        binary_test_target.append(1)\n",
    "    elif train_rating[i] <= 5:\n",
    "        binary_test_target.append(0)\n",
    "print(\"Converted to binary values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing first and last Training records After conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Training ratings:\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Last 10 Training ratings:\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "First 10 Test ratings:\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Last 10 Test ratings:\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#print this to check if all values are converted to binary \n",
    "print(\"First 10 Training ratings:\")\n",
    "for i in range(0,10):\n",
    "    print(binary_train_target[i])\n",
    "print(\"Last 10 Training ratings:\")\n",
    "for i in range(24990,25000):\n",
    "    print(binary_train_target[i])\n",
    "print(\"First 10 Test ratings:\")\n",
    "for i in range(0,10):\n",
    "    print(binary_test_target[i])\n",
    "print(\"Last 10 Test ratings:\")\n",
    "for i in range(24990,25000):\n",
    "    print(binary_test_target[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3456685, 94)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Vectorizing')\n",
    "count_vect_test = CountVectorizer()\n",
    "X_train_counts = count_vect_test.fit_transform(train_review.data)\n",
    "print('Done!')\n",
    "X_train_counts.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing..\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3340173, 86)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Vectorizing..')\n",
    "count_vect_test = CountVectorizer()\n",
    "X_test_counts = count_vect_test.fit_transform(test_review.data)\n",
    "print('Done!')\n",
    "X_test_counts.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done tf for train array\n",
      "Done tfidf for train array\n",
      "Done tf for test array\n",
      "Done tfidf for train array\n",
      "Now converting string files to float..\n",
      "Done Conversion\n"
     ]
    }
   ],
   "source": [
    "tf_transformer = TfidfTransformer().fit(train_review)\n",
    "X_train_tf = tf_transformer.transform(train_review)\n",
    "print('Done tf for train array')\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(train_review)\n",
    "print('Done tfidf for train array')\n",
    "\n",
    "tf_transformer = TfidfTransformer().fit(test_review)\n",
    "X_test_tf = tf_transformer.transform(test_review)\n",
    "print('Done tf for test array') \n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_test_tfidf = tfidf_transformer.fit_transform(test_review)\n",
    "print('Done tfidf for train array')\n",
    "# As the files loaded were in sting now we need float type\n",
    "print('Now converting string files to float..')\n",
    "test_review = test_review.astype(np.float)\n",
    "train_review = train_review.astype(np.float)\n",
    "print(\"Done Conversion\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training On Linear SVM..\n",
      "Done Training\n",
      "Accuracy for Linear SVM Classifier: 87.93% in 1.68 Seconds\n"
     ]
    }
   ],
   "source": [
    "clf_linear = LinearSVC()\n",
    "print(\"Training On Linear SVM..\")\n",
    "\n",
    "start = time()\n",
    "clf_linear.fit(X_train_tfidf,binary_train_target)\n",
    "end = time()\n",
    "\n",
    "print(\"Done Training\")\n",
    "clf_linear_accuracy = clf_linear.score(X_test_tfidf, binary_test_target)*100\n",
    "\n",
    "print('Accuracy for Linear SVM Classifier: %.2f%% in %.2f Seconds'%(clf_linear_accuracy, end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes Multinominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Accuracy for naive bayes: 83.07% in 0.20 Seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf_mnb = MultinomialNB()\n",
    "print(\"Starting\")\n",
    "start = time()\n",
    "clf_mnb = clf_mnb.fit(X_train_tfidf,binary_train_target)\n",
    "end = time()\n",
    "\n",
    "clf_mnb_accuracy = clf_mnb.score(X_test_tfidf, binary_test_target)*100\n",
    "print('Accuracy for naive bayes: %.2f%% in %.2f Seconds'% (clf_mnb_accuracy, end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Accuracy for naive bayes: 82.74% in 0.32 Seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf_bnb = BernoulliNB()\n",
    "print(\"Starting\")\n",
    "start = time()\n",
    "clf_bnb = clf_bnb.fit(X_train_tfidf,binary_train_target)\n",
    "end = time()\n",
    "\n",
    "clf_bnb_accuracy = clf_bnb.score(X_test_tfidf, binary_test_target)*100\n",
    "print('Accuracy for naive bayes: %.2f%% in %.2f Seconds'% (clf_bnb_accuracy, end-start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 65.40% in 2.53 Seconds with 2.00 depth\n",
      "Accuracy = 68.59% in 4.63 Seconds with 4.00 depth\n",
      "Accuracy = 70.44% in 7.45 Seconds with 6.00 depth\n",
      "Accuracy = 71.87% in 11.17 Seconds with 8.00 depth\n",
      "Accuracy = 72.52% in 15.77 Seconds with 10.00 depth\n",
      "Accuracy = 72.51% in 33.23 Seconds with 16.00 depth\n",
      "Accuracy = 72.05% in 44.82 Seconds with 20.00 depth\n",
      "Accuracy = 71.68% in 53.83 Seconds with 26.00 depth\n",
      "Accuracy = 71.66% in 58.27 Seconds with 30.00 depth\n",
      "Accuracy = 70.99% in 73.19 Seconds with 40.00 depth\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "depth = [2,4,6,8,10,16,20,26,30,40]\n",
    "for i in depth:\n",
    "\n",
    "    clf_tree = DecisionTreeClassifier(max_depth=i)\n",
    "    start = time()\n",
    "    clf_tree.fit(X_train_tfidf, binary_train_target)\n",
    "    end = time()\n",
    "\n",
    "    clf_tree_accuracy = clf_tree.score(X_test_tfidf, binary_test_target)*100\n",
    "\n",
    "    print('Accuracy = %.2f%% in %.2f Seconds with %.2f depth'  % (clf_tree_accuracy,end-start,i))\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunning Parameter...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Setting alpha for bernoulli classifier using Grid Search to find best estimator\n",
    "alphas = np.arange(8,9.5,0.01)\n",
    "print('Tunning Parameter...')\n",
    "clf_g =  GridSearchCV(estimator=BernoulliNB(),param_grid=dict(alpha=alphas))\n",
    "clf_g.fit(X_train_tfidf,binary_train_target)\n",
    "print('Done')\n",
    "#save best parameter\n",
    "g_best_alpha = clf_g.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy Before tunning 82.736 and afetr parameter tunning=  82.924\n"
     ]
    }
   ],
   "source": [
    "g_best_alpha.fit(X_train_tfidf, binary_train_target)\n",
    "accu = g_best_alpha.score(X_test_tfidf, binary_test_target)*100\n",
    "\n",
    "print('Test accuracy Before tunning',clf_bnb_accuracy, 'and afetr parameter tunning= ',accu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final prediction using bernoulli with best alpha on test set and saving file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting by burnolis...\n",
      "Done Prediction!\n",
      "file saved as:final_review.csv\n"
     ]
    }
   ],
   "source": [
    "final_array = []\n",
    "file_name = 'final_review.csv'# Change file name here \n",
    "print('Predicting by burnolis...')\n",
    "predicted = g_best_alpha.predict(test_review)\n",
    "print('Done Prediction!')\n",
    "#Adding positive or negative with index of predicted file\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == 0:\n",
    "        final_array.append([i,'Positive'])\n",
    "\n",
    "    elif predicted[i] == 1:\n",
    "        final_array.append([i,'Negative'])\n",
    "#Using pandas library to save file as csv\n",
    "df = pd.DataFrame(data=final_array)\n",
    "df.columns = ['Movie','Rating']\n",
    "df.to_csv(file_name,index=False)\n",
    "print('file saved as:' + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24970</th>\n",
       "      <td>24970</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24971</th>\n",
       "      <td>24971</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24972</th>\n",
       "      <td>24972</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24973</th>\n",
       "      <td>24973</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24974</th>\n",
       "      <td>24974</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24975</th>\n",
       "      <td>24975</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24976</th>\n",
       "      <td>24976</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24977</th>\n",
       "      <td>24977</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24978</th>\n",
       "      <td>24978</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24979</th>\n",
       "      <td>24979</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24980</th>\n",
       "      <td>24980</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24981</th>\n",
       "      <td>24981</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24982</th>\n",
       "      <td>24982</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24983</th>\n",
       "      <td>24983</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24984</th>\n",
       "      <td>24984</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24985</th>\n",
       "      <td>24985</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24986</th>\n",
       "      <td>24986</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24987</th>\n",
       "      <td>24987</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24988</th>\n",
       "      <td>24988</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24989</th>\n",
       "      <td>24989</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>24990</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24991</th>\n",
       "      <td>24991</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24992</th>\n",
       "      <td>24992</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>24993</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>24994</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>24995</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>24996</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>24997</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>24998</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>24999</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Movie    Rating\n",
       "0          0  Negative\n",
       "1          1  Negative\n",
       "2          2  Positive\n",
       "3          3  Positive\n",
       "4          4  Negative\n",
       "5          5  Positive\n",
       "6          6  Negative\n",
       "7          7  Negative\n",
       "8          8  Positive\n",
       "9          9  Negative\n",
       "10        10  Positive\n",
       "11        11  Positive\n",
       "12        12  Negative\n",
       "13        13  Negative\n",
       "14        14  Negative\n",
       "15        15  Negative\n",
       "16        16  Negative\n",
       "17        17  Negative\n",
       "18        18  Negative\n",
       "19        19  Negative\n",
       "20        20  Negative\n",
       "21        21  Negative\n",
       "22        22  Negative\n",
       "23        23  Negative\n",
       "24        24  Negative\n",
       "25        25  Negative\n",
       "26        26  Negative\n",
       "27        27  Negative\n",
       "28        28  Negative\n",
       "29        29  Negative\n",
       "...      ...       ...\n",
       "24970  24970  Positive\n",
       "24971  24971  Positive\n",
       "24972  24972  Positive\n",
       "24973  24973  Positive\n",
       "24974  24974  Negative\n",
       "24975  24975  Negative\n",
       "24976  24976  Positive\n",
       "24977  24977  Positive\n",
       "24978  24978  Positive\n",
       "24979  24979  Positive\n",
       "24980  24980  Positive\n",
       "24981  24981  Positive\n",
       "24982  24982  Positive\n",
       "24983  24983  Positive\n",
       "24984  24984  Positive\n",
       "24985  24985  Positive\n",
       "24986  24986  Positive\n",
       "24987  24987  Positive\n",
       "24988  24988  Positive\n",
       "24989  24989  Positive\n",
       "24990  24990  Positive\n",
       "24991  24991  Positive\n",
       "24992  24992  Positive\n",
       "24993  24993  Negative\n",
       "24994  24994  Positive\n",
       "24995  24995  Positive\n",
       "24996  24996  Positive\n",
       "24997  24997  Positive\n",
       "24998  24998  Positive\n",
       "24999  24999  Positive\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if file saved is in right format\n",
    "test = pd.read_csv(file_name)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "#### Other testing methods used for project\n",
    "##### Parameter Tuning for linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clist = 2**np.array(range(-2, 10), dtype='float')\n",
    "cvscores = []\n",
    "for c in clist:\n",
    "    print('vlaue for C is:')\n",
    "    print(c)\n",
    "    clf = LinearSVC(C=c)\n",
    "    scores = cross_val_score(clf, X_train_tfidf, binary_train_target, cv=3)\n",
    "    print(scores)\n",
    "    cvscores.append(scores.mean()*100)\n",
    "    bestscore, bestC = max([(val, clist[idx]) for (idx, val) in enumerate(cvscores)])\n",
    "\n",
    "print('Best CV accuracy =', bestscore, 'achieved at C =', bestC)\n",
    "\n",
    "clf = LinearSVC(C=bestC)\n",
    "clf.fit(X_train_tfidf, binary_train_target)\n",
    "accu = clf.score(X_test_tfidf, binary_test_target)*100\n",
    "print('Test accuracy =', accu, 'achieved at C =', bestC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setting alpha for bernoulli classifier using Grid Search to find best estimator\n",
    "alphas = 2**np.array(range(-2, 10), dtype='float')\n",
    "print('Tunning Parameter...')\n",
    "clf_g =  GridSearchCV(estimator=BernoulliNB(),param_grid=dict(alpha=alphas))\n",
    "clf_g.fit(X_train_tfidf,binary_train_target)\n",
    "print('Done')\n",
    "#save best parameter\n",
    "g_best_alpha = clf_g.best_estimator_\n",
    "print(g_best_alpha)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing best estimator gives alpha value as 8 so further using cross validation with range 8 to 9 with increment 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alphas = np.arange(8,9.5,0.01)\n",
    "mean_scores = []\n",
    "print(\"tunning....\")\n",
    "\n",
    "for i in alphas:\n",
    "    clf_g =  BernoulliNB(alpha=i)\n",
    "    scores = cross_val_score(clf_g, train_review, binary_train_target, cv=3)\n",
    "    mean_scores.append(scores.mean()*100)\n",
    "    bestmean, bestAlpha = max([(val, alphas[idx]) for (idx, val) in enumerate(mean_scores)])\n",
    "print('Done')\n",
    "clf = BernoulliNB(alpha=i)\n",
    "clf.fit(X_train_tfidf, binary_train_target)\n",
    "accu = clf.score(X_test_tfidf, binary_test_target)*100\n",
    "print('Test accuracy =', accu, 'achieved at alpha =', bestAlpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### References "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset:\n",
    "@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
    "  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
    "  title     = {Learning Word Vectors for Sentiment Analysis},\n",
    "  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
    "  month     = {June},\n",
    "  year      = {2011},\n",
    "  address   = {Portland, Oregon, USA},\n",
    "  publisher = {Association for Computational Linguistics},\n",
    "  pages     = {142--150},\n",
    "  url       = {http://www.aclweb.org/anthology/P11-1015}\n",
    "}\n",
    "\n",
    "Lecture notes \n",
    "scikit learn documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
